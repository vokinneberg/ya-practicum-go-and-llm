---
theme: default
background: /background.jpg
class: text-center
drawings:
  persist: false
transition: slide-left
mdc: true
title: Go –∏ LLM
info: |
  <h2>Go –∏ LLM</h2>
  <h5 class="font-light">–ï–≤–≥–µ–Ω–∏–π –ì—Ä–µ–±–µ–Ω–Ω–∏–∫–æ–≤</h5>
---

<div class="text-center text-4xl">
  Go –∏ LLM
</div>

<div class="text-center text-2xl">
  –ï–≤–≥–µ–Ω–∏–π –ì—Ä–µ–±–µ–Ω–Ω–∏–∫–æ–≤
</div>

<div class="abs-br m-6 flex gap-2 items-center">
  <div class="text-center text-xl flex items-center gap-1">
    {{ new Date().toLocaleDateString('ru-RU', { year: 'numeric', month: 'long', day: 'numeric' }) }}
  </div>
  <a href="https://github.com/vokinneberg/ya-practicum-go-and-llm" target="_blank" alt="GitHub" title="Open in GitHub"
    class="text-xl slidev-icon-btn opacity-50 !border-none !hover:text-white">
    <carbon-logo-github />
  </a>
</div>

---
layout: two-cols
hideInToc: true
---

## ü§ó –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!

- ‚úçÔ∏è –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ—Å—å –≤ Zoom (–ò–º—è –§–∞–º–∏–ª–∏—è)
- üìπ –ö–∞–º–µ—Ä–∞ –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- üí¨ –ü–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –≤ —á–∞—Ç ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º –≤ –∫–æ–Ω—Ü–µ

::right::

## –ü–ª–∞–Ω –≤–µ–±–∏–Ω–∞—Ä–∞

<Toc minDepth="1" maxDepth="1" class="text-left" mode="all" />

---
layout: default
title: –ü–æ—á–µ–º—É Go —Å–µ–π—á–∞—Å –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç
---

# –ü–æ—á–µ–º—É Go —Å–µ–π—á–∞—Å –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç

- üöÄ –ù–∏–∑–∫–∞—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: goroutines, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ GIL
- üîí –¢–∏–ø–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ‚Üí –º–µ–Ω—å—à–µ runtime-–æ—à–∏–±–æ–∫
- üì¶ –û–¥–∏–Ω —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –±–∏–Ω–∞—Ä–Ω–∏–∫
- üõ† –°–∏–ª—å–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ (net/http, sync, pprof)

## –ü—Ä–∏–º–µ—Ä—ã

- OpenAI, Anthropic, Cohere ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ Go SDK
- Cloudflare Workers AI, Elastic, Datadog
- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ LLM-—à–ª—é–∑—ã (FAANG) —Ä–∞–¥–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ—Å—Ç—ã—Ö deploy

---
layout: default
title: –≠–∫–æ—Å–∏—Å—Ç–µ–º–∞
---

# –≠–∫–æ—Å–∏—Å—Ç–µ–º–∞

1. **LLM –∫–ª–∏–µ–Ω—Ç—ã:** `openai-go`, `ollama-go`, `go-anthropic`
2. **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è:** `langchaingo`, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ pipelines, DI (wire/fx)
3. **–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î:** Qdrant, Weaviate, Milvus, Pinecone
4. **–ò–Ω—Ñ—Ä–∞:** Redis/Ristretto, Kafka/NATS, Prometheus, OTEL

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è**: –Ω–∞—á–∏–Ω–∞–µ–º —Å –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–∏.

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## OpenAI Go SDK

```go
import (
    "github.com/openai/openai-go"
    "github.com/openai/openai-go/option"
)

client := openai.NewClient(option.WithAPIKey(apiKey))

resp, err := client.Chat.Completions.New(ctx,
    openai.ChatCompletionNewParams{
        Model: openai.F("gpt-4o-mini"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.UserMessage("Explain Go channels"),
        },
        Temperature: openai.Float(0.2),
    },
)
```

- ‚úÖ JSON mode, function calling, streaming
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ vision, audio, embeddings
- ‚ö†Ô∏è –°—Ç–æ–∏–º–æ—Å—Ç—å –∏ –ª–∏–º–∏—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
- ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–¥—É–º–∞–Ω–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ rate limiting

---
layout: default
layoutClass: gap-6 px-4
---

## –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Ollama

```go
import "github.com/ollama/ollama-go"

client := ollama.NewClient()

resp, err := client.Generate(ctx, &ollama.GenerateRequest{
    Model:  "llama3.1",
    Prompt: "Explain Go concurrency",
    Stream: true,
})
```

- ‚úÖ –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º, –±—ã—Å—Ç—Ä—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- ‚úÖ –ù–µ—Ç API-–ª–∏–º–∏—Ç–æ–≤, –º–æ–∂–Ω–æ fine-tune –≤–µ—Å–∞
- ‚ö†Ô∏è –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å = –≤–∞—à–µ –∂–µ–ª–µ–∑–æ
- ‚ö†Ô∏è –ú–µ–Ω—å—à–µ –º–æ–¥–µ–ª–µ–π, –Ω—É–∂–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞—Ç—å inference-—Å—Ç–µ–∫

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## Langchaingo –∏–ª–∏ —Å–≤–æ–π –º–∏–Ω–∏-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫?

**Langchaingo**
- Chains, agents, tool calling –∏–∑ –∫–æ—Ä–æ–±–∫–∏
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Qdrant, Pinecone, OpenAI
- –£—Å–∫–æ—Ä—è–µ—Ç –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ

**Custom**
- –¢–æ–Ω–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ latencies/cost
- –ú–µ–Ω—å—à–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π ‚Üí –ø—Ä–æ—â–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã `LLMClient`, `Retriever`, `Pipeline`

**–ß–∞—Å—Ç—ã–π –ø—É—Ç—å**: langchaingo –≤ MVP ‚Üí –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –≤—ã–ø–∏–ª–∏–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–¥–µ.

---
layout: center
title: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å
---

# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞

```mermaid {scale: 0.55}
flowchart TD
    gw[API —Å–ª–æ–π<br/>HTTP/gRPC]
    llm[LLM –∫–ª–∏–µ–Ω—Ç<br/>OpenAI/Ollama]
    core[Core / RAG Pipeline]
    vec[Vector DB<br/>Qdrant/Weaviate]
    cache[Cache<br/>Redis/Ristretto]
    obs[Observability<br/>Prometheus ¬∑ OTEL]

    gw --> llm
    llm --> core
    core --> vec
    core --> cache
    gw --> obs
```

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## –ß—ë—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

### LLM-–∫–ª–∏–µ–Ω—Ç

```go
type LLMClient interface {
    Generate(ctx context.Context, prompt Prompt) (Answer, error)
    Stream(ctx context.Context, prompt Prompt) (<-chan Chunk, error)
    Embedding(ctx context.Context, text string) ([]float32, error)
}
```

- –ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
- –î–æ–±–∞–≤–ª—è–µ–º retries, rate limiting, –º–æ–¥–µ—Ä–∞—Ü–∏—é
- –°–Ω–∏–º–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ per model

### Handlers

- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–∞, auth, —Ç—Ä–µ–π—Å–∏–Ω–≥
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (timeout/cancel)
- –û—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É (REST, SSE, gRPC)

–ß–µ–º –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–µ–µ —Å–ª–æ–π, —Ç–µ–º –ø—Ä–æ—â–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å core –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API.

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## Prompts –∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–µ —è–¥—Ä–æ

### –•—Ä–∞–Ω–∏–º –ø—Ä–æ–º–ø—Ç—ã

- –§–∞–π–ª—ã (`prompts/system.txt`) –¥–ª—è MVP
- Config / Feature flag ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã
- –ë–î ‚Äî –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, A/B —Ç–µ—Å—Ç—ã

```go
type Pipeline struct {
    chunker TextChunker
    retriever VectorDatabase
    llm LLMClient
}

func (p *Pipeline) Answer(ctx context.Context, q string) (string, error) {
    emb, err := p.llm.Embedding(ctx, q)
    docs, err := p.retriever.Search(ctx, emb, 4)
    prompt := composePrompt(docs, q)
    return p.llm.Generate(ctx, prompt)
}
```

**Core**: –∫–æ–º–ø–æ–∑–∏—Ü–∏—è —à–∞–≥–æ–≤, –∞ –Ω–µ –º–µ—Å—Ç–æ –¥–ª—è HTTP/SDK-–¥–µ—Ç–∞–ª–µ–π.

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## Streaming –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å

```go
func (h *Handler) Stream(w http.ResponseWriter, r *http.Request) {
    ctx, cancel := context.WithTimeout(r.Context(), 30*time.Second)
    defer cancel()

    setupSSE(w)
    stream, err := h.llm.Stream(ctx, buildPrompt(r))
    if err != nil { handleErr(err); return }

    for chunk := range stream {
        fmt.Fprintf(w, "data:%s\n\n", chunk.Text)
        w.(http.Flusher).Flush()
    }
}
```

```go
func ProcessBatch(ctx context.Context, jobs []Job, workers int) []Result {
    jobCh := make(chan Job, len(jobs))
    resCh := make(chan Result, len(jobs))

    for i := 0; i < workers; i++ {
        go func() {
            for job := range jobCh {
                resCh <- handleJob(ctx, job)
            }
        }()
    }

    for _, job := range jobs { jobCh <- job }
    close(jobCh)

    var out []Result
    for range jobs { out = append(out, <-resCh) }
    return out
}
```

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## –ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å: retry + fallback

```go
func Retry(ctx context.Context, fn func() error) error {
    var lastErr error
    for attempt := 0; attempt < 3; attempt++ {
        if err := fn(); err == nil {
            return nil
        }
        lastErr = err
        backoff := time.Duration(1<<attempt) * time.Second
        if err := sleepCtx(ctx, backoff); err != nil {
            return err
        }
    }
    return fmt.Errorf("retries exceeded: %w", lastErr)
}
```

```go
func (r *Router) Generate(ctx context.Context, q string) (string, error) {
    primary := r.primary.Generate(ctx, q)
    if primary.Err == nil { return primary.Answer, nil }

    if r.cb.Open() {
        return "", fmt.Errorf("provider unhealthy: %w", primary.Err)
    }

    fallback := r.fallback.Generate(ctx, q)
    if fallback.Err != nil {
        r.cb.Fail()
        return "", fallback.Err
    }

    r.cb.Success()
    return fallback.Answer, nil
}
```

Retry budget + circuit breaker –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—é—Ç –∫–∞—Å–∫–∞–¥–Ω—ã–µ –æ—Ç–∫–∞–∑—ã.

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å–µ—Ç—å

### HTTP/2 / HTTP/3

- Multiplexing, header compression
- –ë—ã—Å—Ç—Ä—ã–π handshake ‚Üí –º–µ–Ω—å—à–µ latency
- –í Go –≤–∫–ª—é—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `http2.ConfigureServer`

### Persistent connections

```go
client := &http.Client{
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 20,
        IdleConnTimeout:     90 * time.Second,
    },
    Timeout: 30 * time.Second,
}
```

- –ì–æ—Ç–æ–≤–∏–º `strings.Builder` + `sync.Pool` –¥–ª—è —Å–±–æ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤
- –°—á–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∑–∞—Ä–∞–Ω–µ–µ (`tiktoken-go`) ‚Üí –Ω–µ —Ä–≤—ë–º –ª–∏–º–∏—Ç
- –ü—Ä–æ—Ñ–∏–ª–∏—Ä—É–µ–º `net/http/pprof`: CPU, heap, goroutines
- –†–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–µ–º –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ `sync.WaitGroup`

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ rate limiting


```go
cacheKey := fmt.Sprintf("llm:%s:%s", model, hash(query))
if cached, err := cache.Get(ctx, cacheKey); err == nil {
    return cached, nil
}

answer, err := llm.Generate(ctx, prompt)
cache.Set(ctx, cacheKey, answer, 10*time.Minute)
```

- Redis –¥–ª—è shared cache, Ristretto ‚Äî in-process
- Embeddings –∫—ç—à–∏—Ä—É–µ–º –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞, –æ—Ç–≤–µ—Ç—ã ‚Äî –ø–æ use-case

```go
type LimiterRegistry struct {
    mu sync.RWMutex
    users map[string]*rate.Limiter
}

func (r *LimiterRegistry) Get(user string) *rate.Limiter {
    r.mu.RLock()
    lim, ok := r.users[user]
    r.mu.RUnlock()
    if ok { return lim }

    r.mu.Lock()
    defer r.mu.Unlock()
    lim = rate.NewLimiter(10, 5)
    r.users[user] = lim
    return lim
}
```

–ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ª–∏–º–∏—Ç—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ + per-user –∫–≤–æ—Ç—ã.

---
layout: two-cols-header
layoutClass: gap-6 px-4
title: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã RAG
---

# –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã RAG

### Chunking

```go
type RecursiveChunker struct {
    Size, Overlap int
}

func (c *RecursiveChunker) Chunk(text string) []string {
    var chunks []string
    step := c.Size - c.Overlap
    for i := 0; i < len(text); i += step {
        end := min(i+c.Size, len(text))
        chunks = append(chunks, text[i:end])
    }
    return chunks
}
```

### Embeddings

```go
resp, _ := client.Embeddings.New(ctx, openai.EmbeddingNewParams{
    Model: openai.EmbeddingModel("text-embedding-3-large"),
    Input: openai.EmbeddingNewParamsInputUnion{
        OfString: openai.F(text),
    },
})

vec := make([]float32, len(resp.Data[0].Embedding))
for i, v := range resp.Data[0].Embedding {
    vec[i] = float32(v)
}
```

- –•–µ—à–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç ‚Üí –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –°–ª–µ–¥–∏–º –∑–∞ –ª–∏–º–∏—Ç–∞–º–∏ —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

---
layout: two-cols-header
layoutClass: gap-6 px-4
title: –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î
---

# –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î

### Qdrant

```go
client, _ := qdrant.NewClient(ctx, &qdrant.Config{
    Host: "localhost",
    Port: 6334,
})

client.CreateCollection(ctx, &qdrant.CreateCollection{
    CollectionName: "docs",
    VectorsConfig: qdrant.NewVectorsConfig(
        &qdrant.VectorParams{Size: 3072, Distance: qdrant.Distance_Cosine},
    ),
})
```

- **Weaviate** ‚Äî GraphQL API, hybrid search
- **Milvus** ‚Äî –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ + GPU
- **Elastic/OpenSearch** ‚Äî sparse + dense –≤ –æ–¥–Ω–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ
- **Pinecone** ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é managed

**–•—Ä–∞–Ω–∏–º payload**: `doc_id`, `source`, score.

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## RAG: ingest –∏ retrieve


```go
func (p *Pipeline) Ingest(ctx context.Context, id, text string) error {
    chunks := p.chunker.Chunk(text)
    points := make([]*qdrant.PointStruct, 0, len(chunks))

    for i, chunk := range chunks {
        emb, err := p.llm.Embedding(ctx, chunk)
        if err != nil { return err }
        points = append(points, makePoint(id, i, emb, chunk))
    }
    return p.vector.Upsert(ctx, points)
}
```

```go
func (p *Pipeline) Answer(ctx context.Context, query string) (string, error) {
    emb, err := p.llm.Embedding(ctx, query)
    docs, scores, err := p.vector.Search(ctx, emb, p.searchLimit)
    context := buildContext(docs, scores)
    return p.llm.Generate(ctx, Prompt{
        System: systemPrompt,
        User:   fmt.Sprintf(\"%s\\n\\n–í–æ–ø—Ä–æ—Å: %s\", context, query),
        Format: JSONSchema,
    })
}
```

- –°–ª–µ–¥–∏–º –∑–∞ –ª–∏–º–∏—Ç–æ–º —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ

---
layout: two-cols-header
layoutClass: gap-6 px-4
---

## Structured output –∏ tools


```go
type Answer struct {
    Response   string   `json:"response"`
    Confidence float64  `json:"confidence"`
    Sources    []string `json:"sources"`
}

resp, _ := client.Chat.Completions.New(ctx,
    openai.ChatCompletionNewParams{
        Model: "gpt-4o-mini",
        Messages: messages,
        ResponseFormat: &openai.ChatCompletionResponseFormatParam{
            Type: openai.F(openai.ChatCompletionResponseFormatTypeJSONObject),
        },
    })
json.Unmarshal([]byte(resp.Choices[0].Message.Content), &answer)
```

```go
tools := []openai.ChatCompletionToolParamUnion{
    openai.ChatCompletionToolParam{
        Type: openai.F(openai.ChatCompletionToolTypeFunction),
        Function: openai.FunctionDefinition{
            Name: "get_weather",
            Parameters: map[string]any{
                "type": "object",
                "properties": map[string]any{
                    "location": map[string]string{"type": "string"},
                },
                "required": []string{"location"},
            },
        },
    },
}
```

- –í–∞–ª–∏–¥–∏—Ä—É–µ–º `go-playground/validator`
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ö–µ–º—ã —á–µ—Ä–µ–∑ `invopop/jsonschema` –∏–ª–∏ quicktype

---
layout: two-cols-header
layoutClass: gap-6 px-4
title: Observability
---

# Observability + —Ç–µ—Å—Ç—ã

```go
var llmLatency = prometheus.NewHistogramVec(
    prometheus.HistogramOpts{
        Name: "llm_request_duration_seconds",
        Help: "LLM latency",
        Buckets: prometheus.ExponentialBuckets(0.05, 2, 8),
    },
    []string{"model", "status"},
)

ctx, span := tracer.Start(ctx, "llm.generate")
span.SetAttributes(attribute.String("model", model))
defer span.End()
```

- Snapshot / golden tests –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–π
- –ö–æ–Ω—Ç—Ä–æ–ª—å –¥—Ä–µ–π—Ñ–∞: baseline –æ—Ç–≤–µ—Ç—ã + —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
- –§–µ–π–∫–æ–≤—ã–µ LLM –∫–ª–∏–µ–Ω—Ç—ã (record/replay) –¥–ª—è unit-—Ç–µ—Å—Ç–æ–≤
- –ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–∞ streaming –∏ batch ingest

---
layout: two-cols-header
layoutClass: gap-6 px-4
title:  –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
---

# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã

1. **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** ‚Äî –º–æ–¥–µ—Ä–∞—Ü–∏—è (OpenAI API) + —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã/—Å–∞–Ω–∏—Ç–∞–π–∑–∏–Ω–≥
2. **Cost control** ‚Äî –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∏ per-user –ª–∏–º–∏—Ç—ã, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤, fallback –Ω–∞ –¥–µ—à—ë–≤—ã–µ –º–æ–¥–µ–ª–∏
3. **Event-driven** ‚Äî Kafka/NATS –¥–ª—è batch –∑–∞–¥–∞—á, worker pools —Å ack/retry
4. **Prompt store** ‚Äî –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, feature flags –¥–ª—è —Ä–∞—Å–∫–∞—Ç–∫–∏

–ß–µ–º —Ä–∞–Ω—å—à–µ —Å–æ–±–µ—Ä—ë—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –±—é–¥–∂–µ—Ç, —Ç–µ–º –¥–µ—à–µ–≤–ª–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã.

---
layout: default
---

## –†–µ—Å—É—Ä—Å—ã

- [openai/openai-go](https://github.com/openai/openai-go)
- [tmc/langchaingo](https://github.com/tmc/langchaingo)
- [qdrant/qdrant-go](https://github.com/qdrant/qdrant-go)
- [go.opentelemetry.io/otel](https://go.opentelemetry.io/otel)
- [ya-practicum-go-and-llm](https://github.com/vokinneberg/ya-practicum-go-and-llm)

---
layout: center
title: ü§î –í–æ–ø—Ä–æ—Å—ã?
---

## –°–ø–∞—Å–∏–±–æ!

–í–æ–ø—Ä–æ—Å—ã? –ü–∏—à–∏—Ç–µ @vokinneberg –≤ Telegram –∏–ª–∏ –æ—Å—Ç–∞–≤–ª—è–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.

<PoweredBySlidev mt-10 />
